{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0835784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2818/1601000250.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2025-10-28 18:33:04.814686: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-28 18:33:04.864114: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-28 18:33:04.864175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-28 18:33:04.867353: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-28 18:33:04.877666: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-28 18:33:04.878859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-28 18:33:05.743979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba9d592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path   label\n",
      "0  [0.26666668, 0.32941177, 0.21568628, 0.2627451...  damage\n",
      "1  [0.4117647, 0.40392157, 0.3137255, 0.43137255,...  damage\n",
      "2  [0.3019608, 0.34901962, 0.3019608, 0.29803923,...  damage\n",
      "3  [0.47058824, 0.48235294, 0.36862746, 0.4588235...  damage\n",
      "4  [0.23137255, 0.32941177, 0.1764706, 0.21176471...  damage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of                                               image_path      label\n",
       "0      [0.26666668, 0.32941177, 0.21568628, 0.2627451...     damage\n",
       "1      [0.4117647, 0.40392157, 0.3137255, 0.43137255,...     damage\n",
       "2      [0.3019608, 0.34901962, 0.3019608, 0.29803923,...     damage\n",
       "3      [0.47058824, 0.48235294, 0.36862746, 0.4588235...     damage\n",
       "4      [0.23137255, 0.32941177, 0.1764706, 0.21176471...     damage\n",
       "...                                                  ...        ...\n",
       "21317  [0.32156864, 0.34509805, 0.23529412, 0.3372549...  no_damage\n",
       "21318  [0.1764706, 0.23137255, 0.16470589, 0.18431373...  no_damage\n",
       "21319  [0.2, 0.25490198, 0.15686275, 0.22745098, 0.28...  no_damage\n",
       "21320  [0.35686275, 0.3882353, 0.29411766, 0.36078432...  no_damage\n",
       "21321  [0.5254902, 0.54901963, 0.4392157, 0.49803922,...  no_damage\n",
       "\n",
       "[21322 rows x 2 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"damage\", \"no_damage\"]\n",
    "\n",
    "data = []\n",
    "for folder in folders:\n",
    "    folder_path = folder\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(folder_path, fname)\n",
    "            # Load the RGB image (128x128)\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img_array = img_to_array(img) / 255.0  # normalize\n",
    "            img_array = img_array.flatten()  # flatten for ANN\n",
    "            data.append({\n",
    "                \"image_path\": img_array,   # store pixel array instead of path\n",
    "                \"label\": folder\n",
    "            })\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "print(data.head())\n",
    "data.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07417472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21322 entries, 0 to 21321\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_path  21322 non-null  object\n",
      " 1   label       21322 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 333.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca83878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42644"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5770461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"damage/-93.795_30.03779.jpeg\")\n",
    "img.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51f8ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           damage\n",
       "1           damage\n",
       "2           damage\n",
       "3           damage\n",
       "4           damage\n",
       "           ...    \n",
       "21317    no_damage\n",
       "21318    no_damage\n",
       "21319    no_damage\n",
       "21320    no_damage\n",
       "21321    no_damage\n",
       "Name: label, Length: 21322, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a07e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].astype(\"string\")\n",
    "data = pd.get_dummies(data, columns=[\"label\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c65c177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'label_no_damage'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe16a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                               image_path  label_no_damage\n",
       "0      [0.26666668, 0.32941177, 0.21568628, 0.2627451...            False\n",
       "1      [0.4117647, 0.40392157, 0.3137255, 0.43137255,...            False\n",
       "2      [0.3019608, 0.34901962, 0.3019608, 0.29803923,...            False\n",
       "3      [0.47058824, 0.48235294, 0.36862746, 0.4588235...            False\n",
       "4      [0.23137255, 0.32941177, 0.1764706, 0.21176471...            False\n",
       "...                                                  ...              ...\n",
       "21317  [0.32156864, 0.34509805, 0.23529412, 0.3372549...             True\n",
       "21318  [0.1764706, 0.23137255, 0.16470589, 0.18431373...             True\n",
       "21319  [0.2, 0.25490198, 0.15686275, 0.22745098, 0.28...             True\n",
       "21320  [0.35686275, 0.3882353, 0.29411766, 0.36078432...             True\n",
       "21321  [0.5254902, 0.54901963, 0.4392157, 0.49803922,...             True\n",
       "\n",
       "[21322 rows x 2 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651c4aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21322 entries, 0 to 21321\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   image_path       21322 non-null  object\n",
      " 1   label_no_damage  21322 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 333.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_path         0\n",
       "label_no_damage    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label_no_damage'] = data['label_no_damage'].apply(lambda x: 1 if x == False else 0)\n",
    "data.info()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfe5301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                               image_path  label_no_damage\n",
       "0      [0.26666668, 0.32941177, 0.21568628, 0.2627451...                1\n",
       "1      [0.4117647, 0.40392157, 0.3137255, 0.43137255,...                1\n",
       "2      [0.3019608, 0.34901962, 0.3019608, 0.29803923,...                1\n",
       "3      [0.47058824, 0.48235294, 0.36862746, 0.4588235...                1\n",
       "4      [0.23137255, 0.32941177, 0.1764706, 0.21176471...                1\n",
       "...                                                  ...              ...\n",
       "21317  [0.32156864, 0.34509805, 0.23529412, 0.3372549...                0\n",
       "21318  [0.1764706, 0.23137255, 0.16470589, 0.18431373...                0\n",
       "21319  [0.2, 0.25490198, 0.15686275, 0.22745098, 0.28...                0\n",
       "21320  [0.35686275, 0.3882353, 0.29411766, 0.36078432...                0\n",
       "21321  [0.5254902, 0.54901963, 0.4392157, 0.49803922,...                0\n",
       "\n",
       "[21322 rows x 2 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05ec93",
   "metadata": {},
   "source": [
    "Damage is 1, no damage is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1835fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X = np.stack(data[\"image_path\"].values)\n",
    "Y = data[\"label_no_damage\"].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0002c5-54ab-4962-992a-b34dc5cce021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                               image_path  label_no_damage\n",
       "0      [0.26666668, 0.32941177, 0.21568628, 0.2627451...                1\n",
       "1      [0.4117647, 0.40392157, 0.3137255, 0.43137255,...                1\n",
       "2      [0.3019608, 0.34901962, 0.3019608, 0.29803923,...                1\n",
       "3      [0.47058824, 0.48235294, 0.36862746, 0.4588235...                1\n",
       "4      [0.23137255, 0.32941177, 0.1764706, 0.21176471...                1\n",
       "...                                                  ...              ...\n",
       "21317  [0.32156864, 0.34509805, 0.23529412, 0.3372549...                0\n",
       "21318  [0.1764706, 0.23137255, 0.16470589, 0.18431373...                0\n",
       "21319  [0.2, 0.25490198, 0.15686275, 0.22745098, 0.28...                0\n",
       "21320  [0.35686275, 0.3882353, 0.29411766, 0.36078432...                0\n",
       "21321  [0.5254902, 0.54901963, 0.4392157, 0.49803922,...                0\n",
       "\n",
       "[21322 rows x 2 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9facae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 18:10:14.993101: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2347499520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 18s - loss: 1.8405 - accuracy: 0.5931 - val_loss: 0.5878 - val_accuracy: 0.7018 - 18s/epoch - 196ms/step\n",
      "Epoch 2/10\n",
      "94/94 - 17s - loss: 0.6173 - accuracy: 0.6745 - val_loss: 0.6778 - val_accuracy: 0.5635 - 17s/epoch - 181ms/step\n",
      "Epoch 3/10\n",
      "94/94 - 17s - loss: 0.5745 - accuracy: 0.7109 - val_loss: 0.5521 - val_accuracy: 0.7427 - 17s/epoch - 181ms/step\n",
      "Epoch 4/10\n",
      "94/94 - 17s - loss: 0.5819 - accuracy: 0.7140 - val_loss: 0.7207 - val_accuracy: 0.6754 - 17s/epoch - 184ms/step\n",
      "Epoch 5/10\n",
      "94/94 - 17s - loss: 0.5922 - accuracy: 0.6922 - val_loss: 0.5555 - val_accuracy: 0.7430 - 17s/epoch - 182ms/step\n",
      "Epoch 6/10\n",
      "94/94 - 17s - loss: 0.5565 - accuracy: 0.7308 - val_loss: 0.5844 - val_accuracy: 0.6905 - 17s/epoch - 181ms/step\n",
      "Epoch 7/10\n",
      "94/94 - 17s - loss: 0.5620 - accuracy: 0.7225 - val_loss: 0.5476 - val_accuracy: 0.7524 - 17s/epoch - 182ms/step\n",
      "Epoch 8/10\n",
      "94/94 - 17s - loss: 0.5528 - accuracy: 0.7322 - val_loss: 0.5570 - val_accuracy: 0.7303 - 17s/epoch - 183ms/step\n",
      "Epoch 9/10\n",
      "94/94 - 17s - loss: 0.5411 - accuracy: 0.7436 - val_loss: 0.5694 - val_accuracy: 0.7273 - 17s/epoch - 181ms/step\n",
      "Epoch 10/10\n",
      "94/94 - 17s - loss: 0.5483 - accuracy: 0.7353 - val_loss: 0.5371 - val_accuracy: 0.7668 - 17s/epoch - 182ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a169b726a90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANN\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(128*128*3,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d1fa945-d647-47b2-87d3-d85bdb5af3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 512)               25166336  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25314177 (96.57 MB)\n",
      "Trainable params: 25314177 (96.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c438bac4-fb8b-4c9b-afe5-2a6519b5436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a1e00b1-13f0-4332-9379-aff2d600a246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5169948], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "925cf312-d06b-4aeb-8724-5a7aad664156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6397"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "959e7dd2-8e95-4b59-beef-95e62daa0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred_final=[]\n",
    "for i in y_pred:\n",
    "    # return the index with the highest probability\n",
    "    if i > .50:\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9289e171-a0fc-48fb-a59e-19c0ef954ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm=confusion_matrix(Y_test,y_pred_final)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1ce2fe6-ec85-4204-ba8b-7d9e01b99c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.42      0.52      2146\n",
      "           1       0.76      0.91      0.83      4251\n",
      "\n",
      "    accuracy                           0.75      6397\n",
      "   macro avg       0.73      0.66      0.68      6397\n",
      "weighted avg       0.74      0.75      0.73      6397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c431cd-2843-48f7-a6e7-93eb0cdf502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path   label\n",
      "0  [[[0.26666668, 0.32941177, 0.21568628], [0.262...  damage\n",
      "1  [[[0.4117647, 0.40392157, 0.3137255], [0.43137...  damage\n",
      "2  [[[0.3019608, 0.34901962, 0.3019608], [0.29803...  damage\n",
      "3  [[[0.47058824, 0.48235294, 0.36862746], [0.458...  damage\n",
      "4  [[[0.23137255, 0.32941177, 0.1764706], [0.2117...  damage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of                                               image_path      label\n",
       "0      [[[0.26666668, 0.32941177, 0.21568628], [0.262...     damage\n",
       "1      [[[0.4117647, 0.40392157, 0.3137255], [0.43137...     damage\n",
       "2      [[[0.3019608, 0.34901962, 0.3019608], [0.29803...     damage\n",
       "3      [[[0.47058824, 0.48235294, 0.36862746], [0.458...     damage\n",
       "4      [[[0.23137255, 0.32941177, 0.1764706], [0.2117...     damage\n",
       "...                                                  ...        ...\n",
       "21317  [[[0.32156864, 0.34509805, 0.23529412], [0.337...  no_damage\n",
       "21318  [[[0.1764706, 0.23137255, 0.16470589], [0.1843...  no_damage\n",
       "21319  [[[0.2, 0.25490198, 0.15686275], [0.22745098, ...  no_damage\n",
       "21320  [[[0.35686275, 0.3882353, 0.29411766], [0.3607...  no_damage\n",
       "21321  [[[0.5254902, 0.54901963, 0.4392157], [0.49803...  no_damage\n",
       "\n",
       "[21322 rows x 2 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"damage\", \"no_damage\"]\n",
    "\n",
    "dataCNN = []\n",
    "for folder in folders:\n",
    "    folder_path = folder\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(folder_path, fname)\n",
    "            # Load the RGB image (128x128)\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img_array = img_to_array(img) / 255.0  # normalize\n",
    "            dataCNN.append({\n",
    "                \"image_path\": img_array,   # store pixel array instead of path\n",
    "                \"label\": folder\n",
    "            })\n",
    "\n",
    "dataCNN = pd.DataFrame(dataCNN)\n",
    "print(dataCNN.head())\n",
    "dataCNN.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f077990-7f79-46de-bcb6-caaece2d31b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42644"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCNN.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a033c75b-50ce-41e1-a017-a1bdcb7cc34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataCNN['image_path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad264db-4176-4f6b-93dc-f3f7c53d5bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCNN['image_path'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a0c50d-f972-48f5-b722-606e9519929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCNN['label'] = dataCNN['label'].astype(\"string\")\n",
    "dataCNN = pd.get_dummies(dataCNN, columns=[\"label\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ae76d1-6b2b-4351-a7ea-e01dda623098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21322 entries, 0 to 21321\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   image_path       21322 non-null  object\n",
      " 1   label_no_damage  21322 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 333.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_path         0\n",
       "label_no_damage    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCNN['label_no_damage'] = dataCNN['label_no_damage'].apply(lambda x: 1 if x == False else 0)\n",
    "dataCNN.info()\n",
    "dataCNN.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59be0822-1c55-41e4-80e2-778a26fbbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X = np.stack(dataCNN[\"image_path\"].values)\n",
    "Y = dataCNN[\"label_no_damage\"].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7db21c-afbd-466e-a4d4-842fc31dc8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14925, 128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3bd1fd-346f-432a-9ec6-dfb6d3e28073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 18:34:20.693392: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2347499520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 156s - loss: 0.5677 - accuracy: 0.7118 - val_loss: 0.4760 - val_accuracy: 0.7360 - 156s/epoch - 2s/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m model_cnn\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     30\u001b[0m model_cnn\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing all the different layers and optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Intializing a sequential model\n",
    "model_cnn = Sequential()\n",
    "\n",
    "# Adding first conv layer with 64 filters and kernel size 3x3 , padding 'same' provides the output size same as the input size\n",
    "# Input_shape denotes input image dimension of MNIST images\n",
    "model_cnn.add(Conv2D(64, (4, 4), activation='relu', padding=\"same\", input_shape=(128, 128, 3)))\n",
    "# Adding max pooling to reduce the size of output of first conv layer\n",
    "model_cnn.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "model_cnn.add(Conv2D(32, (4, 4), activation='relu', padding=\"same\"))\n",
    "model_cnn.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "model_cnn.add(Conv2D(32, (4, 4), activation='relu', padding=\"same\"))\n",
    "model_cnn.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "# flattening the output of the conv layer after max pooling to make it ready for creating dense connections\n",
    "model_cnn.add(Flatten())\n",
    "\n",
    "# Adding a fully connected dense layer with 100 neurons\n",
    "model_cnn.add(Dense(100, activation='relu'))\n",
    "\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=128, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d1890-31b4-4936-89ff-cf4975372e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
